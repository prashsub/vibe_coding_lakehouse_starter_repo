# =============================================================================
# ML Manifest
# =============================================================================
# Generated by: planning/00-project-planning (stage 5)
# Consumed by:  ml/00-ml-pipeline-setup (stage 8)
#
# This manifest defines all ML models, feature tables, and experiments that the
# ML orchestrator should create. It is generated from the plan addendum
# (phase1-addendum-1.1-ml-models.md) and the Gold layer YAML schemas.
#
# Usage:
#   1. Fill in the template below during Planning (stage 5)
#   2. Save as: plans/manifests/ml-manifest.yaml
#   3. The ML orchestrator reads this at Phase 0
#   4. If this file doesn't exist, the orchestrator falls back to self-discovery
# =============================================================================

version: 1
manifest_type: ml
generated_from:
  gold_yaml_dir: gold_layer_design/yaml/
  plan_addendums:
    - plans/phase1-addendum-1.1-ml-models.md

# -----------------------------------------------------------------------------
# Global settings
# -----------------------------------------------------------------------------
catalog: ${catalog}
gold_schema: ${gold_schema}
feature_schema: ${feature_schema}   # Schema for feature tables

# -----------------------------------------------------------------------------
# Feature Tables
# Define feature tables that aggregate Gold layer data for model training
# -----------------------------------------------------------------------------
feature_tables:
  - name: "{domain}_features"
    description: "Features for {domain} ML models"
    primary_keys:
      - "{entity_id}"
      - "{date_column}"
    source_gold_tables:
      - "fact_{entity}"
      - "dim_{entity}"
    features:
      - name: "{metric}_7d_avg"
        type: DOUBLE
        description: "7-day rolling average of {metric}"
        derivation: "AVG({metric_column}) OVER (PARTITION BY {entity_id} ORDER BY {date_column} ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)"
      - name: "{metric}_30d_total"
        type: DOUBLE
        description: "30-day cumulative {metric}"
        derivation: "SUM({metric_column}) OVER (PARTITION BY {entity_id} ORDER BY {date_column} ROWS BETWEEN 29 PRECEDING AND CURRENT ROW)"
      - name: "{entity}_age_days"
        type: DOUBLE
        description: "Days since {entity} creation"
        derivation: "DATEDIFF(CURRENT_DATE, {creation_date_column})"

# -----------------------------------------------------------------------------
# Models
# Organized by domain, matching agent domain framework
# -----------------------------------------------------------------------------
models:
  # ---------------------------------------------------------------------------
  # Domain models
  # ---------------------------------------------------------------------------
  - name: "{domain}_{purpose}_{type}"
    domain: "{domain}"
    description: "{What this model predicts/detects}"
    model_type: "{classification|regression|anomaly_detection}"
    algorithm: "XGBClassifier"    # or XGBRegressor, IsolationForest, etc.
    feature_table: "{domain}_features"
    label_column: "{label_column}"
    label_type: "{INT|DOUBLE}"    # INT for classification, DOUBLE for regression
    label_derivation: "{How label is computed from Gold tables}"
    business_questions:
      - "Which {entities} are likely to {prediction}?"
      - "What is the predicted {metric} for next {period}?"
    evaluation_metrics:
      - "{accuracy|rmse|f1_score|precision|recall|auc}"
    training_schedule: "weekly"
    inference_schedule: "daily"

# -----------------------------------------------------------------------------
# Experiments (MLflow)
# One experiment per model following /Shared/ path convention
# -----------------------------------------------------------------------------
experiments:
  - name: "/Shared/{project}_ml_{model_name}"
    model: "{domain}_{purpose}_{type}"
    description: "Training experiments for {model description}"

# -----------------------------------------------------------------------------
# Asset Bundle Jobs
# Three standard jobs per ML project
# -----------------------------------------------------------------------------
jobs:
  feature_pipeline:
    name: "ml_feature_pipeline_job"
    schedule: "daily"
    description: "Creates/refreshes all feature tables from Gold layer"
    tasks:
      - task_key: "create_feature_tables"
        notebook: "src/{project}_ml/features/create_feature_tables.py"

  training_pipeline:
    name: "ml_training_pipeline_job"
    schedule: "weekly"
    description: "Trains all models in parallel"
    tasks:
      # One task per model â€” add as many as needed
      - task_key: "train_{model_name}"
        notebook: "src/{project}_ml/{domain}/train_{model_name}.py"

  inference_pipeline:
    name: "ml_inference_pipeline_job"
    schedule: "daily"
    description: "Batch inference using fe.score_batch for all models"
    tasks:
      - task_key: "batch_inference"
        notebook: "src/{project}_ml/inference/batch_inference_all_models.py"

# -----------------------------------------------------------------------------
# Summary counts (for validation)
# Fill in after populating all domains
# -----------------------------------------------------------------------------
summary:
  total_feature_tables: "{N}"
  total_models: "{N}"
  total_experiments: "{N}"
  models_by_type:
    classification: "{N}"
    regression: "{N}"
    anomaly_detection: "{N}"
