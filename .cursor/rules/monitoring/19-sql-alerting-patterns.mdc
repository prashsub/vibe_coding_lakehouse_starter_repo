---
description: Comprehensive guide for Databricks SQL Alerts - config-driven alerting framework with SDK deployment
globs: **/*alert*.py,**/*alert*.yml
alwaysApply: false
---

# SQL Alerting: Config-Driven Framework for Databricks

## üìã Table of Contents

1. [Core Principles](#core-principles)
2. [Alert ID Convention](#alert-id-convention)
3. [Alert Rules Configuration Table](#alert-rules-configuration-table)
4. [SQL Query Patterns](#sql-query-patterns)
5. [Databricks SDK Integration](#databricks-sdk-integration)
6. [DAB Job Configuration](#dab-job-configuration)
7. [Complete Examples](#complete-examples)
8. [Troubleshooting](#troubleshooting)
9. [References](#references)

---

## Core Principles

### Principle 1: Config-Driven Alerting
Alert rules are stored in a Delta configuration table, not hardcoded. This enables:
- Runtime updates without code changes
- Centralized alert management
- Version history via Delta time travel
- Easy enable/disable without deployment

### Principle 2: Two-Job Pattern
**‚ö†Ô∏è CRITICAL:** Alerting uses a two-job separation of concerns:

1. **Setup Job** (`alert_rules_setup_job`): Creates/updates the `alert_rules` config table
2. **Deploy Job** (`alert_deploy_job`): Reads config table and creates/updates SQL Alerts via SDK

**Why This Matters:**
- Rules can be modified in Delta without redeploying alerts
- Dry-run capability for validation
- Clear separation between configuration and deployment

### Principle 3: Fully Qualified Table Names
**‚ö†Ô∏è CRITICAL:** Databricks SQL Alerts (Public Preview) do NOT support parameters in queries.

```sql
-- ‚ùå WRONG: Parameterized query (NOT SUPPORTED)
SELECT * FROM ${catalog}.${schema}.fact_booking_daily

-- ‚úÖ CORRECT: Fully qualified table names embedded in query
SELECT * FROM wanderbricks_dev.gold.fact_booking_daily
```

**Pattern:** Use f-strings at rule creation time to embed catalog/schema:

```python
rev_001_query = f"""
SELECT ...
FROM {catalog}.{gold_schema}.fact_booking_daily
WHERE ...
"""
```

### Principle 4: Severity-Based Notification Routing
Alerts are categorized by severity with different notification strategies:

| Severity | Icon | Action Required | Notification Speed |
|----------|------|-----------------|-------------------|
| CRITICAL | üî¥ | Immediate | Real-time (email + Slack) |
| WARNING | üü° | Investigate soon | Batched (email) |
| INFO | üü¢ | Informational | Daily digest |

---

## Alert ID Convention

### Format: `<DOMAIN>-<NUMBER>-<SEVERITY>`

**Components:**
- `DOMAIN`: Business domain (3-4 chars)
- `NUMBER`: Sequential within domain (3 digits, zero-padded)
- `SEVERITY`: CRIT, WARN, or INFO

### Domain Prefixes

| Domain | Prefix | Description | Example |
|--------|--------|-------------|---------|
| Revenue | REV | Bookings, payments, cancellations | REV-001-CRIT |
| Engagement | ENG | Traffic, conversion, views | ENG-002-WARN |
| Property | PROP | Inventory, pricing, listings | PROP-003-INFO |
| Host | HOST | Ratings, verification, activity | HOST-001-CRIT |
| Customer | CUST | Signups, churn, segments | CUST-004-INFO |

### Examples

```
REV-001-CRIT  ‚Üí Revenue domain, alert #1, critical severity
ENG-003-WARN  ‚Üí Engagement domain, alert #3, warning severity
PROP-004-INFO ‚Üí Property domain, alert #4, informational
```

### Naming in Databricks UI

Alert display names follow pattern: `[SEVERITY] Alert Name`

```python
alert_name = f"[{rule['severity']}] {rule['alert_name']}"
# Result: "[CRITICAL] Revenue Drop Alert"
```

---

## Alert Rules Configuration Table

### Schema Definition

```sql
CREATE TABLE IF NOT EXISTS {catalog}.{gold_schema}.alert_rules (
    -- Primary Key
    alert_id STRING NOT NULL
        COMMENT 'Unique identifier for the alert rule (format: DOMAIN-NUMBER-SEVERITY)',
    
    -- Alert Identity
    alert_name STRING NOT NULL
        COMMENT 'Human-readable display name for the alert',
    domain STRING NOT NULL
        COMMENT 'Business domain: revenue, engagement, property, host, customer',
    severity STRING NOT NULL
        COMMENT 'Alert severity: CRITICAL, WARNING, INFO',
    alert_description STRING NOT NULL
        COMMENT 'Detailed description of what this alert monitors',
    
    -- Query Configuration
    alert_query STRING NOT NULL
        COMMENT 'SQL query that returns data when condition is met',
    condition_column STRING NOT NULL
        COMMENT 'Column name to evaluate in alert condition',
    condition_operator STRING NOT NULL
        COMMENT 'Comparison operator: >, <, >=, <=, =, !=',
    condition_threshold STRING NOT NULL
        COMMENT 'Threshold value for condition comparison',
    aggregation_type STRING
        COMMENT 'Optional aggregation: SUM, AVG, COUNT, MIN, MAX, FIRST',
    
    -- Schedule Configuration
    schedule_cron STRING NOT NULL
        COMMENT 'Quartz cron expression for schedule',
    schedule_timezone STRING NOT NULL
        COMMENT 'IANA timezone identifier',
    
    -- Notification Configuration
    notification_emails STRING
        COMMENT 'Comma-separated email addresses',
    notification_slack_channel STRING
        COMMENT 'Slack channel for notifications',
    custom_subject_template STRING
        COMMENT 'Custom email subject template',
    custom_body_template STRING
        COMMENT 'Custom notification body template',
    notify_on_ok BOOLEAN NOT NULL
        COMMENT 'Send notification when alert returns to OK status',
    rearm_seconds INT
        COMMENT 'Cooldown period in seconds before re-triggering',
    
    -- Control
    is_enabled BOOLEAN NOT NULL
        COMMENT 'Whether this alert is active',
    tags STRING
        COMMENT 'JSON-formatted tags for categorization',
    owner STRING NOT NULL
        COMMENT 'Email of alert owner/maintainer',
    
    -- Audit
    record_created_timestamp TIMESTAMP NOT NULL,
    record_updated_timestamp TIMESTAMP NOT NULL,
    
    CONSTRAINT pk_alert_rules PRIMARY KEY (alert_id) NOT ENFORCED
)
USING DELTA
CLUSTER BY AUTO
TBLPROPERTIES (
    'delta.enableChangeDataFeed' = 'true',
    'layer' = 'gold',
    'domain' = 'alerting',
    'entity_type' = 'config',
    'config_table' = 'true'
)
```

### Required Columns for SDK Deployment

| Column | SDK Field | Required | Notes |
|--------|-----------|----------|-------|
| `alert_query` | `query_text` | ‚úÖ | Full SQL query |
| `condition_column` | `AlertOperandColumn.name` | ‚úÖ | Column to check |
| `condition_operator` | `AlertConditionOperator` | ‚úÖ | >, <, =, etc. |
| `condition_threshold` | `AlertOperandValue.string_value` | ‚úÖ | Threshold value |
| `schedule_cron` | `cron_schedule` | ‚úÖ | Quartz format |
| `schedule_timezone` | `cron_timezone` | ‚úÖ | IANA timezone |

---

## SQL Query Patterns

### Pattern 1: Threshold Comparison (Most Common)

**Use Case:** Alert when metric crosses a threshold

```sql
-- REV-002-CRIT: High Cancellation Rate (>15%)
SELECT 
    DATE_ADD(CURRENT_DATE(), -1) as check_in_date,
    SUM(cancellation_count) as cancellations,
    SUM(booking_count) as bookings,
    ROUND(SUM(cancellation_count) / NULLIF(SUM(booking_count), 0) * 100, 1) as cancellation_rate,
    'CRITICAL: Cancellation rate at ' || 
        ROUND(SUM(cancellation_count) / NULLIF(SUM(booking_count), 0) * 100, 1) || 
        '% (' || SUM(cancellation_count) || ' of ' || SUM(booking_count) || ' bookings)' as alert_message
FROM {catalog}.{gold_schema}.fact_booking_daily
WHERE check_in_date = DATE_ADD(CURRENT_DATE(), -1)
HAVING SUM(cancellation_count) / NULLIF(SUM(booking_count), 0) > 0.15
```

**Key Elements:**
- `condition_column`: `cancellation_rate`
- `condition_operator`: `>`
- `condition_threshold`: `15`
- Returns rows ONLY when condition is met (via HAVING clause)
- Includes `alert_message` column for notification content

### Pattern 2: Percentage Change from Baseline

**Use Case:** Alert when metric deviates from historical average

```sql
-- REV-001-CRIT: Revenue Drop (>20% below 7-day average)
SELECT 
    CURRENT_DATE() as alert_date,
    yesterday_revenue,
    avg_7d_revenue,
    ROUND((yesterday_revenue - avg_7d_revenue) / avg_7d_revenue * 100, 1) as pct_change,
    'CRITICAL: Revenue dropped ' || 
        ROUND((avg_7d_revenue - yesterday_revenue) / avg_7d_revenue * 100, 1) || 
        '% below 7-day average ($' || FORMAT_NUMBER(yesterday_revenue, 2) || 
        ' vs avg $' || FORMAT_NUMBER(avg_7d_revenue, 2) || ')' as alert_message
FROM (
    SELECT
        SUM(CASE WHEN check_in_date = DATE_ADD(CURRENT_DATE(), -1) 
            THEN total_booking_value ELSE 0 END) as yesterday_revenue,
        AVG(CASE WHEN check_in_date BETWEEN DATE_ADD(CURRENT_DATE(), -8) 
            AND DATE_ADD(CURRENT_DATE(), -2) 
            THEN daily_total ELSE NULL END) as avg_7d_revenue
    FROM (
        SELECT check_in_date, SUM(total_booking_value) as daily_total
        FROM {catalog}.{gold_schema}.fact_booking_daily
        WHERE check_in_date >= DATE_ADD(CURRENT_DATE(), -8)
        GROUP BY 1
    )
)
WHERE yesterday_revenue < avg_7d_revenue * 0.8
```

### Pattern 3: Statistical Anomaly Detection (Z-Score)

**Use Case:** Alert when metric is statistically unusual

```sql
-- REV-003-WARN: Booking Volume Anomaly (>2 std from mean)
SELECT 
    CURRENT_TIMESTAMP() as alert_time,
    today_bookings,
    ROUND(avg_bookings, 0) as avg_bookings,
    ROUND(stddev_bookings, 0) as stddev_bookings,
    ROUND((today_bookings - avg_bookings) / NULLIF(stddev_bookings, 0), 1) as z_score,
    'WARNING: Booking volume anomaly - ' || today_bookings || ' bookings (' ||
        ROUND((today_bookings - avg_bookings) / NULLIF(stddev_bookings, 0), 1) || 
        ' std deviations from 30-day mean of ' || ROUND(avg_bookings, 0) || ')' as alert_message
FROM (
    SELECT
        SUM(CASE WHEN check_in_date = CURRENT_DATE() 
            THEN booking_count ELSE 0 END) as today_bookings,
        AVG(daily_bookings) as avg_bookings,
        STDDEV(daily_bookings) as stddev_bookings
    FROM (
        SELECT check_in_date, SUM(booking_count) as daily_bookings
        FROM {catalog}.{gold_schema}.fact_booking_daily
        WHERE check_in_date BETWEEN DATE_ADD(CURRENT_DATE(), -30) AND CURRENT_DATE()
        GROUP BY 1
    )
)
WHERE ABS(today_bookings - avg_bookings) > 2 * stddev_bookings
  AND stddev_bookings > 0  -- Prevent division by zero
```

### Pattern 4: Count-Based Alert (Low Activity)

**Use Case:** Alert when count is below threshold

```sql
-- ENG-003-WARN: Low Engagement Properties (<10 views in 7 days)
SELECT 
    COUNT(*) as low_engagement_count,
    CONCAT_WS(', ', COLLECT_LIST(CAST(property_id AS STRING))) as property_ids,
    'WARNING: ' || COUNT(*) || ' properties have <10 views in past 7 days' as alert_message
FROM (
    SELECT 
        p.property_id,
        COALESCE(SUM(e.view_count), 0) as weekly_views
    FROM {catalog}.{gold_schema}.dim_property p
    LEFT JOIN {catalog}.{gold_schema}.fact_property_engagement e
        ON p.property_id = e.property_id
        AND e.engagement_date >= DATE_ADD(CURRENT_DATE(), -7)
    WHERE p.is_current = true
    GROUP BY p.property_id
    HAVING COALESCE(SUM(e.view_count), 0) < 10
)
HAVING COUNT(*) > 0  -- Only alert if there are affected properties
```

### Pattern 5: Informational Summary (Always Triggers)

**Use Case:** Daily/weekly summary reports

```sql
-- REV-005-INFO: Daily Revenue Summary
SELECT 
    DATE_ADD(CURRENT_DATE(), -1) as date,
    SUM(total_booking_value) as total_revenue,
    SUM(booking_count) as total_bookings,
    ROUND(AVG(avg_booking_value), 2) as avg_booking_value,
    1 as always_trigger,  -- ‚úÖ Always returns 1 for INFO alerts
    'Daily Summary: $' || FORMAT_NUMBER(SUM(total_booking_value), 2) || 
        ' revenue from ' || SUM(booking_count) || ' bookings' as alert_message
FROM {catalog}.{gold_schema}.fact_booking_daily
WHERE check_in_date = DATE_ADD(CURRENT_DATE(), -1)
```

**Key:** For INFO alerts that should always trigger, include a column like `always_trigger` set to `1`, with condition `condition_column='always_trigger', condition_operator='=', condition_threshold='1'`.

### Query Design Rules

1. **Always include `alert_message`**: Human-readable notification content
2. **Use `NULLIF()` for division**: Prevent division by zero errors
3. **Filter with WHERE + HAVING**: WHERE for time ranges, HAVING for threshold filtering
4. **Include context in message**: Actual values, thresholds, and percentages
5. **Use `FORMAT_NUMBER()` for currency**: Proper formatting in messages

---

## Databricks SDK Integration

### Import Pattern

```python
from databricks.sdk import WorkspaceClient
from databricks.sdk.service.sql import (
    AlertCondition,
    AlertConditionOperand,
    AlertConditionThreshold,
    AlertOperandColumn,
    AlertOperandValue,
    AlertConditionOperator,
)
```

### Operator Mapping

```python
def get_operator_enum(operator_str: str) -> AlertConditionOperator:
    """Convert string operator to AlertConditionOperator enum."""
    operator_map = {
        ">": AlertConditionOperator.GREATER_THAN,
        ">=": AlertConditionOperator.GREATER_THAN_OR_EQUAL,
        "<": AlertConditionOperator.LESS_THAN,
        "<=": AlertConditionOperator.LESS_THAN_OR_EQUAL,
        "=": AlertConditionOperator.EQUAL,
        "==": AlertConditionOperator.EQUAL,
        "!=": AlertConditionOperator.NOT_EQUAL,
        "<>": AlertConditionOperator.NOT_EQUAL,
    }
    return operator_map.get(operator_str, AlertConditionOperator.GREATER_THAN)
```

### Creating an Alert

```python
def create_alert(ws: WorkspaceClient, rule: dict, warehouse_id: str):
    """Create a SQL Alert from a rule configuration."""
    
    # Build condition
    condition = AlertCondition(
        op=get_operator_enum(rule["condition_operator"]),
        operand=AlertConditionOperand(
            column=AlertOperandColumn(name=rule["condition_column"])
        ),
        threshold=AlertConditionThreshold(
            value=AlertOperandValue(
                string_value=str(rule["condition_threshold"])
            )
        )
    )
    
    # Create alert
    new_alert = ws.alerts.create(
        display_name=f"[{rule['severity']}] {rule['alert_name']}",
        query_text=rule["alert_query"],
        warehouse_id=warehouse_id,
        condition=condition,
        cron_schedule=rule["schedule_cron"],
        cron_timezone=rule["schedule_timezone"],
        notify_on_ok=rule.get("notify_on_ok", False),
        custom_subject=rule.get("custom_subject_template"),
        custom_body=rule.get("custom_body_template"),
    )
    
    return new_alert
```

### Listing Existing Alerts

```python
def get_existing_alerts(ws: WorkspaceClient) -> dict:
    """Get all existing alerts keyed by display name."""
    existing = {}
    try:
        alerts = ws.alerts.list()
        for alert in alerts:
            if alert.display_name:
                existing[alert.display_name] = alert
    except Exception as e:
        print(f"Warning: Could not list existing alerts: {e}")
    return existing
```

### Idempotent Deployment Pattern

```python
def deploy_alert(ws: WorkspaceClient, rule: dict, warehouse_id: str, 
                 existing_alerts: dict, dry_run: bool = False):
    """Deploy alert with idempotency check."""
    
    alert_name = f"[{rule['severity']}] {rule['alert_name']}"
    existing = existing_alerts.get(alert_name)
    
    if dry_run:
        if existing:
            print(f"[DRY RUN] Would update: {existing.id}")
        else:
            print(f"[DRY RUN] Would create new alert")
        return {"status": "dry_run"}
    
    if existing:
        # Alert exists - skip or update
        # Note: Delete and recreate for updates (SDK limitation)
        print(f"Alert exists: {existing.id} - skipping")
        return {"status": "skipped", "id": existing.id}
    
    # Create new alert
    new_alert = create_alert(ws, rule, warehouse_id)
    return {"status": "created", "id": new_alert.id}
```

---

## DAB Job Configuration

### Setup Job (Create/Update Config Table)

```yaml
# resources/gold/alert_rules_setup_job.yml
resources:
  jobs:
    alert_rules_setup_job:
      name: "[${bundle.target}] Wanderbricks Alert Rules - Setup"
      description: "Creates alert_rules configuration table with alert definitions"
      
      environments:
        - environment_key: default
          spec:
            environment_version: "4"
      
      tasks:
        - task_key: setup_alert_rules
          environment_key: default
          notebook_task:
            notebook_path: ../../src/wanderbricks_gold/alerting/setup_alert_rules.py
            base_parameters:
              catalog: ${var.catalog}
              gold_schema: ${var.gold_schema}
          timeout_seconds: 1800
      
      email_notifications:
        on_failure:
          - data-engineering@company.com
      
      tags:
        environment: ${bundle.target}
        project: wanderbricks
        layer: gold
        job_type: setup
        component: alerting
        compute_type: serverless
```

### Deploy Job (Create SQL Alerts from Config)

```yaml
# resources/gold/alert_deploy_job.yml
resources:
  jobs:
    alert_deploy_job:
      name: "[${bundle.target}] Wanderbricks Alert - Deploy"
      description: "Deploys SQL alerts from alert_rules configuration table"
      
      environments:
        - environment_key: default
          spec:
            environment_version: "4"
            dependencies:
              - "databricks-sdk>=0.28.0"  # Required for alerts API
      
      tasks:
        - task_key: deploy_alerts
          environment_key: default
          notebook_task:
            notebook_path: ../../src/wanderbricks_gold/alerting/deploy_alerts.py
            base_parameters:
              catalog: ${var.catalog}
              gold_schema: ${var.gold_schema}
              warehouse_id: ${var.warehouse_id}
              dry_run: "false"
          timeout_seconds: 1800
      
      email_notifications:
        on_failure:
          - data-engineering@company.com
        on_success:
          - data-engineering@company.com
      
      tags:
        environment: ${bundle.target}
        project: wanderbricks
        layer: gold
        job_type: deployment
        component: alerting
        compute_type: serverless
```

### Key Configuration Points

1. **SDK Dependency**: Deploy job requires `databricks-sdk>=0.28.0`
2. **Warehouse ID**: Required for SQL Alert execution
3. **Dry Run**: Enable for validation without creating alerts
4. **Serverless**: Both jobs use serverless compute

---

## Complete Examples

### Example 1: Critical Revenue Alert

```python
{
    "alert_id": "REV-001-CRIT",
    "alert_name": "Revenue Drop Alert",
    "domain": "revenue",
    "severity": "CRITICAL",
    "alert_description": "Triggers when daily revenue drops below 80% of 7-day average.",
    "alert_query": """
        SELECT 
            CURRENT_DATE() as alert_date,
            yesterday_revenue,
            avg_7d_revenue,
            ROUND((yesterday_revenue - avg_7d_revenue) / avg_7d_revenue * 100, 1) as pct_change,
            'CRITICAL: Revenue dropped ' || 
                ROUND((avg_7d_revenue - yesterday_revenue) / avg_7d_revenue * 100, 1) || 
                '% below 7-day average' as alert_message
        FROM (
            SELECT
                SUM(CASE WHEN check_in_date = DATE_ADD(CURRENT_DATE(), -1) 
                    THEN total_booking_value ELSE 0 END) as yesterday_revenue,
                AVG(CASE WHEN check_in_date BETWEEN DATE_ADD(CURRENT_DATE(), -8) 
                    AND DATE_ADD(CURRENT_DATE(), -2) 
                    THEN daily_total ELSE NULL END) as avg_7d_revenue
            FROM (
                SELECT check_in_date, SUM(total_booking_value) as daily_total
                FROM catalog.gold.fact_booking_daily
                WHERE check_in_date >= DATE_ADD(CURRENT_DATE(), -8)
                GROUP BY 1
            )
        )
        WHERE yesterday_revenue < avg_7d_revenue * 0.8
    """,
    "condition_column": "pct_change",
    "condition_operator": "<",
    "condition_threshold": "-20",
    "aggregation_type": "FIRST",
    "schedule_cron": "0 0 6 * * ?",  # Daily at 6 AM
    "schedule_timezone": "America/Los_Angeles",
    "notification_emails": "finance@company.com,revenue@company.com",
    "notification_slack_channel": "#revenue-alerts",
    "custom_subject_template": "[{{ALERT_STATUS}}] CRITICAL: {{ALERT_NAME}}",
    "custom_body_template": """Alert: {{ALERT_NAME}}
Time: {{ALERT_TIME}}
Status: {{ALERT_STATUS}}

{{QUERY_RESULT_VALUE}}

Action Required: Investigate immediately.

View Alert: {{ALERT_URL}}""",
    "notify_on_ok": True,
    "rearm_seconds": 1800,  # 30 min cooldown
    "is_enabled": True,
    "tags": '{"team": "finance", "priority": "p1"}',
    "owner": "data-engineering@company.com"
}
```

### Example 2: Warning Engagement Alert

```python
{
    "alert_id": "ENG-002-WARN",
    "alert_name": "Conversion Rate Drop",
    "domain": "engagement",
    "severity": "WARNING",
    "alert_description": "Triggers when average conversion rate falls below 2%.",
    "alert_query": """
        SELECT 
            DATE_ADD(CURRENT_DATE(), -1) as date,
            ROUND(AVG(conversion_rate), 2) as avg_conversion,
            COUNT(*) as property_count,
            'WARNING: Conversion rate at ' || 
                ROUND(AVG(conversion_rate), 2) || '% (threshold: 2%)' as alert_message
        FROM catalog.gold.fact_property_engagement
        WHERE engagement_date = DATE_ADD(CURRENT_DATE(), -1)
        HAVING AVG(conversion_rate) < 2
    """,
    "condition_column": "avg_conversion",
    "condition_operator": "<",
    "condition_threshold": "2",
    "aggregation_type": "FIRST",
    "schedule_cron": "0 0 8 * * ?",  # Daily at 8 AM
    "schedule_timezone": "America/Los_Angeles",
    "notification_emails": "growth@company.com",
    "notification_slack_channel": "#marketing-alerts",
    "custom_subject_template": "[{{ALERT_STATUS}}] Warning: {{ALERT_NAME}}",
    "custom_body_template": """Alert: {{ALERT_NAME}}
Time: {{ALERT_TIME}}
Status: {{ALERT_STATUS}}

{{QUERY_RESULT_VALUE}}

Please investigate at your earliest convenience.

View Alert: {{ALERT_URL}}""",
    "notify_on_ok": True,
    "rearm_seconds": 3600,
    "is_enabled": True,
    "tags": '{"team": "growth", "priority": "p2"}',
    "owner": "data-engineering@company.com"
}
```

### Example 3: Info Summary Alert

```python
{
    "alert_id": "REV-005-INFO",
    "alert_name": "Daily Revenue Summary",
    "domain": "revenue",
    "severity": "INFO",
    "alert_description": "Daily informational summary of revenue metrics.",
    "alert_query": """
        SELECT 
            DATE_ADD(CURRENT_DATE(), -1) as date,
            SUM(total_booking_value) as total_revenue,
            SUM(booking_count) as total_bookings,
            ROUND(AVG(avg_booking_value), 2) as avg_booking_value,
            1 as always_trigger,
            'Daily Summary: $' || FORMAT_NUMBER(SUM(total_booking_value), 2) || 
                ' revenue from ' || SUM(booking_count) || ' bookings' as alert_message
        FROM catalog.gold.fact_booking_daily
        WHERE check_in_date = DATE_ADD(CURRENT_DATE(), -1)
    """,
    "condition_column": "always_trigger",
    "condition_operator": "=",
    "condition_threshold": "1",
    "aggregation_type": "FIRST",
    "schedule_cron": "0 0 9 * * ?",  # Daily at 9 AM
    "schedule_timezone": "America/Los_Angeles",
    "notification_emails": "leadership@company.com",
    "notification_slack_channel": "#daily-metrics",
    "custom_subject_template": "[INFO] {{ALERT_NAME}}",
    "custom_body_template": """Daily Summary: {{ALERT_NAME}}
Time: {{ALERT_TIME}}

{{QUERY_RESULT_TABLE}}

View Details: {{ALERT_URL}}""",
    "notify_on_ok": False,
    "rearm_seconds": None,
    "is_enabled": True,
    "tags": '{"team": "leadership", "priority": "p3"}',
    "owner": "data-engineering@company.com"
}
```

---

## Custom Notification Templates

### Available Variables

| Variable | Description |
|----------|-------------|
| `{{ALERT_NAME}}` | Display name of the alert |
| `{{ALERT_STATUS}}` | Current status: TRIGGERED, OK, ERROR |
| `{{ALERT_TIME}}` | Timestamp when alert was evaluated |
| `{{QUERY_RESULT_VALUE}}` | Single value from query result |
| `{{QUERY_RESULT_TABLE}}` | Full table of query results |
| `{{ALERT_URL}}` | Link to alert in Databricks UI |

### Critical Template

```
Alert: {{ALERT_NAME}}
Time: {{ALERT_TIME}}
Status: {{ALERT_STATUS}}

{{QUERY_RESULT_VALUE}}

‚ö†Ô∏è Action Required: Investigate immediately.

View Alert: {{ALERT_URL}}
```

### Warning Template

```
Alert: {{ALERT_NAME}}
Time: {{ALERT_TIME}}
Status: {{ALERT_STATUS}}

{{QUERY_RESULT_VALUE}}

Please investigate at your earliest convenience.

View Alert: {{ALERT_URL}}
```

### Info Template

```
Summary: {{ALERT_NAME}}
Time: {{ALERT_TIME}}

{{QUERY_RESULT_TABLE}}

View Details: {{ALERT_URL}}
```

---

## Schedule Patterns (Quartz Cron)

### Common Schedules

| Pattern | Cron Expression | Description |
|---------|-----------------|-------------|
| Daily at 6 AM | `0 0 6 * * ?` | Morning critical alerts |
| Hourly | `0 0 * * * ?` | Frequent monitoring |
| Every 15 min | `0 0/15 * * * ?` | High-frequency alerts |
| Weekly Monday 9 AM | `0 0 9 ? * MON` | Weekly summaries |
| Business hours | `0 0 9-17 * * ?` | 9 AM to 5 PM hourly |

### Timezone Considerations

Always use IANA timezone identifiers:
- `America/Los_Angeles` (Pacific)
- `America/New_York` (Eastern)
- `UTC` (Coordinated Universal Time)
- `America/Chicago` (Central)

---

## Troubleshooting

### Problem: Alert Not Triggering

**Symptoms:** Alert is enabled but never sends notifications

**Diagnosis Steps:**
1. Run the alert query manually - does it return rows?
2. Check condition: does returned value satisfy operator + threshold?
3. Verify warehouse is running when schedule fires
4. Check notification destination configuration

**Common Fixes:**
```sql
-- Debug: Run query and check condition column value
SELECT *, 
    CASE 
        WHEN {condition_column} {operator} {threshold} THEN 'WOULD_TRIGGER'
        ELSE 'NO_TRIGGER'
    END as would_trigger
FROM ({alert_query})
```

### Problem: Alert Always Triggering

**Symptoms:** Getting notifications even when condition shouldn't be met

**Diagnosis:**
- Query returns rows even when condition isn't met
- Missing HAVING clause
- Wrong operator direction

**Fix:** Add HAVING clause to filter results:
```sql
-- ‚ùå WRONG: Returns rows always
SELECT rate FROM ... WHERE rate IS NOT NULL

-- ‚úÖ CORRECT: Only returns rows when threshold crossed
SELECT rate FROM ... HAVING rate > 15
```

### Problem: "Query Failed" Error Status

**Symptoms:** Alert shows ERROR status

**Common Causes:**
1. Table doesn't exist (wrong catalog/schema)
2. Column doesn't exist
3. SQL syntax error
4. Warehouse unavailable

**Debug:**
```python
# Test query in notebook first
spark.sql(f"""
    {alert_query}
""").display()
```

### Problem: SDK Permission Error

**Symptoms:** `PermissionDenied` when creating alerts

**Fix:** Ensure service principal or user has:
- `CAN_MANAGE` permission on SQL Warehouse
- `CAN_CREATE` permission for SQL Alerts
- `CAN_USE` on catalog and schema

### Problem: Duplicate Alerts Created

**Symptoms:** Multiple alerts with same name

**Fix:** Check existing alerts before creating:
```python
existing = get_existing_alerts(ws)
if alert_name not in existing:
    ws.alerts.create(...)
```

---

## Best Practices

### ‚úÖ DO

1. **Use config table for all rules** - Never hardcode alert configurations
2. **Include `alert_message` column** - Human-readable notification content
3. **Test queries manually first** - Verify in notebook before adding to config
4. **Use NULLIF for division** - Prevent division by zero errors
5. **Set appropriate rearm periods** - Prevent alert fatigue (1800-3600 seconds)
6. **Enable notify_on_ok for critical** - Know when issues are resolved
7. **Use dry_run for validation** - Test deployment without creating alerts

### ‚ùå DON'T

1. **Don't use parameters in queries** - SQL Alerts don't support `${param}` syntax
2. **Don't skip the HAVING clause** - Queries should only return rows when alerting
3. **Don't set rearm too low** - Causes notification spam
4. **Don't hardcode credentials** - Use WorkspaceClient() for auto-auth
5. **Don't skip schema validation** - Verify alert_rules table exists before deploying

---

## Workflow Summary

### Initial Setup

```bash
# 1. Deploy alert rules table
databricks bundle run alert_rules_setup_job -t dev

# 2. Verify rules
# SELECT * FROM {catalog}.{gold_schema}.alert_rules

# 3. Deploy alerts (dry run first)
# Edit dry_run: "true" in job config
databricks bundle run alert_deploy_job -t dev

# 4. Deploy alerts (for real)
# Edit dry_run: "false" in job config
databricks bundle run alert_deploy_job -t dev
```

### Adding New Alerts

1. Add rule to `get_alert_rules()` function in `setup_alert_rules.py`
2. Run setup job: `databricks bundle run alert_rules_setup_job -t dev`
3. Run deploy job: `databricks bundle run alert_deploy_job -t dev`

### Modifying Existing Alerts

1. Update rule in config table or `setup_alert_rules.py`
2. Run setup job to update config table
3. Delete existing alert in Databricks UI
4. Run deploy job to recreate with new configuration

---

## References

- [Databricks SQL Alerts Documentation](https://docs.databricks.com/sql/user/alerts/)
- [Alert Notifications](https://docs.databricks.com/sql/user/alerts/index.html#notifications)
- [Databricks SDK - Alerts API](https://databricks-sdk-py.readthedocs.io/en/latest/)
- [Quartz Cron Expression Format](http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html)

---

**Last Updated:** December 2024  
**Pattern Origin:** Wanderbricks Platform - Config-driven alerting framework  
**Key Lesson:** Always use fully qualified table names in alert queries - parameters are NOT supported
