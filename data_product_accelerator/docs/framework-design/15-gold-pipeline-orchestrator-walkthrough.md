# Gold Pipeline Orchestrator â€” Visual Walkthrough

How the `01-gold-layer-setup` orchestrator progressively loads 5 pipeline-worker skills across 6 phases, transforming YAML schema designs into production-ready Delta tables with MERGE scripts, FK constraints, and Asset Bundle jobs â€” all driven by extraction from YAML, never generation from memory.

> **Related skills:** [`01-gold-layer-setup`](../../skills/gold/01-gold-layer-setup/SKILL.md), [`01-yaml-table-setup`](../../skills/gold/pipeline-workers/01-yaml-table-setup/SKILL.md), [`02-merge-patterns`](../../skills/gold/pipeline-workers/02-merge-patterns/SKILL.md), [`03-deduplication`](../../skills/gold/pipeline-workers/03-deduplication/SKILL.md), [`04-grain-validation`](../../skills/gold/pipeline-workers/04-grain-validation/SKILL.md), [`05-schema-validation`](../../skills/gold/pipeline-workers/05-schema-validation/SKILL.md)
>
> **Predecessor:** [`00-gold-layer-design`](../../skills/gold/00-gold-layer-design/SKILL.md) â€” YAML schemas must exist before this skill runs

---

## The Agent's Journey Through the Gold Pipeline Orchestrator

### Step 0: Skill Activation (~100 tokens)

When a user says something like *"Implement the Gold layer from the YAML designs"*, the agent matches:

```yaml
name: gold-layer-setup
description: >
  End-to-end orchestrator for implementing Gold layer tables, merge scripts, FK constraints,
  and Asset Bundle jobs from YAML schema definitions...
```

Keywords "Gold layer", "YAML", "merge scripts", "FK constraints", "Asset Bundle" match. The agent reads the full SKILL.md (~530 lines).

### Step 1: The Prerequisite Check

Before anything else, the orchestrator verifies that the Gold Design phase is complete:

```
MANDATORY prerequisites from gold/00-gold-layer-design:
  âœ… YAML schema files in gold_layer_design/yaml/{domain}/*.yaml
  âœ… ERD documentation (erd_master.md)
  âœ… Column lineage documentation (COLUMN_LINEAGE.csv)

  âŒ Missing any of these â†’ STOP. Run design skill first.
```

### Step 2: The Guard Rails Lock In

The Gold Pipeline orchestrator has 6 non-negotiable defaults plus the cardinal extraction rule:

| Default | Value | NEVER Do This Instead |
|---------|-------|-----------------------|
| **Serverless** | `environments:` block with `environment_key` | Never define `job_clusters:` |
| **Environments V4** | `environment_version: "4"` | Never omit or use older versions |
| **Auto Liquid Clustering** | `CLUSTER BY AUTO` | Never use `CLUSTER BY (col1, col2)` |
| **Change Data Feed** | `delta.enableChangeDataFeed: "true"` | Never omit |
| **Row Tracking** | `delta.enableRowTracking: "true"` | Never omit |
| **notebook_task** | `notebook_task:` with `base_parameters:` | Never use `python_task:` |

**The Cardinal Rule â€” Extraction Over Generation:**

```
EVERY value MUST be extracted from Gold YAML files or COLUMN_LINEAGE.csv.
NEVER generate, guess, or hardcode.

Extracted from YAML:  table names, column names/types, PKs, FKs,
                      business keys, grain types, SCD types,
                      source Silver tables, column mappings

Coded by hand:        ONLY aggregation expressions and derived
                      column formulas (business logic)
```

This is the single most important constraint in the entire orchestrator â€” it prevents hallucinated table/column names that would cause runtime failures.

### Step 3: The Progressive Disclosure Protocol

```
Read skills ONLY when entering the phase that needs them:
  Phase 0: No skills â€” run validation script
  Phase 1: Read 01-yaml-table-setup + table-properties + unity-catalog + schema-mgmt
  Phase 2: Read 02-merge-patterns + 03-deduplication + 04-grain-validation +
           05-schema-validation + python-imports
  Phase 3: Read asset-bundles â†’ work â†’ persist notes â†’ DISCARD all
  Phase 4-5: User-triggered deployment and validation
```

**At each phase boundary, the agent's working memory should contain ONLY:**
1. Table inventory dict (extracted from YAML in Phase 1 â€” persists through all phases)
2. Previous phase's summary note
3. Current phase's worker skills (read just-in-time)

---

## Phase 0: Upstream Contract Validation â€” The Pre-Flight Check

Before writing a single line of implementation code, the agent validates that all Silver â†’ Gold column mappings are correct. This catches the most common source of iteration.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 0                             â”‚
â”‚                                                          â”‚
â”‚  No worker skills needed â€” runs validation script        â”‚
â”‚                                                          â”‚
â”‚  Execute: scripts/validate_upstream_contracts.py         â”‚
â”‚                                                          â”‚
â”‚  For each Gold YAML file:                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ dim_customer.yaml                        â”‚            â”‚
â”‚  â”‚   lineage:                               â”‚            â”‚
â”‚  â”‚     customer_name:                       â”‚            â”‚
â”‚  â”‚       silver_table: silver_customers     â”‚            â”‚
â”‚  â”‚       silver_column: cust_name           â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ Check: does silver_customers.cust_name   â”‚            â”‚
â”‚  â”‚        actually exist in the catalog?    â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ âœ… PASSED â€” column exists                â”‚            â”‚
â”‚  â”‚ âŒ FAILED â€” fix YAML before proceeding   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  GATE: ALL contracts must show PASSED                   â”‚
â”‚  Backup: merge template also embeds this check as       â”‚
â”‚  fail-fast in main()                                     â”‚
â”‚                                                          â”‚
â”‚  ðŸ“ Persist: pass/fail per table, any YAML fixes         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: YAML-Driven Table Creation

The agent creates a single generic script that reads ALL YAML files and generates tables dynamically â€” no table-specific code.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 1                             â”‚
â”‚                                                          â”‚
â”‚  Working Memory:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ Phase 0 notes (pass/fail)    â”‚                       â”‚
â”‚  â”‚ 01-yaml-table-setup SKILL    â”‚ â† READ now (worker)   â”‚
â”‚  â”‚ table-properties SKILL       â”‚ â† READ now (common)   â”‚
â”‚  â”‚ unity-catalog-constraints    â”‚ â† READ now (common)   â”‚
â”‚  â”‚ schema-management-patterns   â”‚ â† READ now (common)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                          â”‚
â”‚  Creates: setup_tables.py (generic, reads YAML)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚  def find_yaml_base():                  â”‚            â”‚
â”‚  â”‚      # Discover YAML directory           â”‚            â”‚
â”‚  â”‚      # (synced via databricks.yml)       â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚  For each *.yaml in yaml/**/:           â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚            â”‚
â”‚  â”‚  â”‚ 1. Parse YAML â†’ table_name,    â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    columns, PKs, FKs, props    â”‚     â”‚            â”‚
â”‚  â”‚  â”‚                                â”‚     â”‚            â”‚
â”‚  â”‚  â”‚ 2. Build DDL dynamically:      â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    CREATE OR REPLACE TABLE     â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    {catalog}.{gold_schema}.    â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    {table_name} (              â”‚     â”‚            â”‚
â”‚  â”‚  â”‚      {col} {type} {NOT NULL},  â”‚     â”‚            â”‚
â”‚  â”‚  â”‚      ...                       â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    )                           â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    CLUSTER BY AUTO     ðŸ”´      â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    TBLPROPERTIES (...)  ðŸ”´      â”‚     â”‚            â”‚
â”‚  â”‚  â”‚                                â”‚     â”‚            â”‚
â”‚  â”‚  â”‚ 3. Apply PK constraint:        â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    ALTER TABLE ADD CONSTRAINT  â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    pk_{table} PRIMARY KEY      â”‚     â”‚            â”‚
â”‚  â”‚  â”‚    ({pk_cols}) NOT ENFORCED    â”‚     â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  Creates: add_fk_constraints.py                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Runs AFTER all PKs exist:               â”‚            â”‚
â”‚  â”‚ ALTER TABLE ADD CONSTRAINT              â”‚            â”‚
â”‚  â”‚   fk_{table}_{col} FOREIGN KEY ({col})  â”‚            â”‚
â”‚  â”‚   REFERENCES {ref_table}({ref_col})     â”‚            â”‚
â”‚  â”‚   NOT ENFORCED                          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  ðŸ“ Persist: table inventory dict, YAML base path,      â”‚
â”‚     count of tables, any FK failures                     â”‚
â”‚                                                          â”‚
â”‚  ðŸ—‘ï¸ DISCARD: Phase 1 skills (keep table inventory)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 1b: Advanced Setup Patterns (If Applicable)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1b (optional)                    â”‚
â”‚                                                          â”‚
â”‚  Execution order matters:                               â”‚
â”‚                                                          â”‚
â”‚  1. Create tables â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1                     â”‚
â”‚  2. Apply PKs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1                     â”‚
â”‚  3. Role-playing views â”€â”€â”€â”€ Phase 1b                    â”‚
â”‚     dim_date â†’ dim_order_date, dim_ship_date            â”‚
â”‚  4. Unknown member rows â”€â”€â”€ Phase 1b                    â”‚
â”‚     INSERT (-1, "Unknown", ...) per dimension           â”‚
â”‚  5. Apply FKs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1                     â”‚
â”‚  6. Run merge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 2                     â”‚
â”‚                                                          â”‚
â”‚  âš ï¸ Unknown members BEFORE FKs â€” prevents NULL FKs     â”‚
â”‚     for late-arriving facts                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 2: MERGE Script Implementation â€” The Core Build

This is the longest and most complex phase (~2 hours). The agent loads 4 worker skills simultaneously and builds merge logic for every table.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 2                             â”‚
â”‚                                                          â”‚
â”‚  Working Memory:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ table_inventory (Phase 1)    â”‚ â† persists forever    â”‚
â”‚  â”‚ Phase 1 notes (paths, PKs)   â”‚                       â”‚
â”‚  â”‚ 02-merge-patterns SKILL      â”‚ â† READ now            â”‚
â”‚  â”‚ 03-deduplication SKILL       â”‚ â† READ now            â”‚
â”‚  â”‚ 04-grain-validation SKILL    â”‚ â† READ now            â”‚
â”‚  â”‚ 05-schema-validation SKILL   â”‚ â† READ now            â”‚
â”‚  â”‚ python-imports SKILL         â”‚ â† READ now (common)   â”‚
â”‚  â”‚ references/advanced-merge    â”‚                       â”‚
â”‚  â”‚ references/design-to-pipelineâ”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚  âš ï¸ Peak context load of the orchestrator               â”‚
â”‚                                                          â”‚
â”‚  Step 0 â€” EXTRACTION FIRST (before any code):           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ For each YAML file:                      â”‚            â”‚
â”‚  â”‚   meta = load_table_metadata(yaml_path)  â”‚            â”‚
â”‚  â”‚   â†’ table_name, pk_columns, business_key â”‚            â”‚
â”‚  â”‚   â†’ scd_type, grain, columns, lineage    â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ Load COLUMN_LINEAGE.csv:                 â”‚            â”‚
â”‚  â”‚   mappings = load_column_mappings()      â”‚            â”‚
â”‚  â”‚   â†’ silver_col â†’ gold_col renames        â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ Build column expressions automatically:  â”‚            â”‚
â”‚  â”‚   build_column_expressions(meta)         â”‚            â”‚
â”‚  â”‚   â†’ automates ~70% of .withColumn() callsâ”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  For each DIMENSION table:                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 1. Check dimension_pattern from YAML:    â”‚            â”‚
â”‚  â”‚    â”œâ”€â”€ role_playing â†’ no merge (views)   â”‚            â”‚
â”‚  â”‚    â”œâ”€â”€ junk â†’ use junk-populate template â”‚            â”‚
â”‚  â”‚    â””â”€â”€ standard â†’ SCD merge below        â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 2. DEDUPLICATE (MANDATORY â€” from 03):    â”‚            â”‚
â”‚  â”‚    .orderBy(col("processed_timestamp")   â”‚            â”‚
â”‚  â”‚      .desc())                            â”‚            â”‚
â”‚  â”‚    .dropDuplicates(meta["business_key"]) â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 3. Map columns (from YAML lineage):      â”‚            â”‚
â”‚  â”‚    .withColumn(gold_col, col(silver_col))â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 4. Generate surrogate key:               â”‚            â”‚
â”‚  â”‚    md5(concat_ws("||", *business_key))   â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 5. SCD columns (if scd_type == "scd2"):  â”‚            â”‚
â”‚  â”‚    effective_from, effective_to, is_curr  â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 6. validate_merge_schema() (from 05)     â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 7. MERGE on business_key (from YAML)     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  For each FACT table:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ 1. Check grain_type from YAML:           â”‚            â”‚
â”‚  â”‚    â”œâ”€â”€ accumulating_snapshot â†’ template   â”‚            â”‚
â”‚  â”‚    â”œâ”€â”€ factless â†’ INSERT only            â”‚            â”‚
â”‚  â”‚    â”œâ”€â”€ periodic_snapshot â†’ period replaceâ”‚            â”‚
â”‚  â”‚    â””â”€â”€ standard â†’ aggregate merge below  â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 2. Aggregate to match grain:             â”‚            â”‚
â”‚  â”‚    .groupBy(meta["pk_columns"])          â”‚            â”‚
â”‚  â”‚    .agg(spark_sum(...), ...)             â”‚            â”‚
â”‚  â”‚    â† spark_sum, not sum (shadows!)       â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 3. Validate grain (from 04):             â”‚            â”‚
â”‚  â”‚    One row per PK combination            â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 4. validate_merge_schema() (from 05)     â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ 5. MERGE on pk_columns (from YAML)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  âš ï¸ Merge dimensions FIRST, then facts                  â”‚
â”‚     (dependency order from YAML foreign_keys)            â”‚
â”‚                                                          â”‚
â”‚  ðŸ“ Persist: merge function inventory (which tables     â”‚
â”‚     use SCD1 vs SCD2, aggregated vs transaction),       â”‚
â”‚     any column mapping issues                            â”‚
â”‚                                                          â”‚
â”‚  ðŸ—‘ï¸ DISCARD: All 4 worker skills + references          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 3: Asset Bundle Configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 3                             â”‚
â”‚                                                          â”‚
â”‚  Working Memory:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ table_inventory              â”‚                       â”‚
â”‚  â”‚ Phase 2 notes (merge inv.)   â”‚                       â”‚
â”‚  â”‚ asset-bundles SKILL.md       â”‚ â† READ now            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚  (Phase 2 skills GONE â€” 2000+ lines freed)              â”‚
â”‚                                                          â”‚
â”‚  Creates two job configurations:                        â”‚
â”‚                                                          â”‚
â”‚  gold_setup_job.yml                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  tasks:                                     â”‚         â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚         â”‚
â”‚  â”‚   â”‚ setup_gold_tables        â”‚â”€â”€â”           â”‚         â”‚
â”‚  â”‚   â”‚ (notebook_task)          â”‚  â”‚           â”‚         â”‚
â”‚  â”‚   â”‚ base_parameters:         â”‚  â”‚           â”‚         â”‚
â”‚  â”‚   â”‚   catalog, gold_schema   â”‚  â”‚           â”‚         â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚           â”‚         â”‚
â”‚  â”‚                    depends_on â”€â”€â–¼           â”‚         â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚         â”‚
â”‚  â”‚   â”‚ add_fk_constraints       â”‚              â”‚         â”‚
â”‚  â”‚   â”‚ (notebook_task)          â”‚              â”‚         â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                          â”‚
â”‚  gold_merge_job.yml                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  tasks:                                     â”‚         â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚         â”‚
â”‚  â”‚   â”‚ merge_gold_tables        â”‚              â”‚         â”‚
â”‚  â”‚   â”‚ (notebook_task)          â”‚              â”‚         â”‚
â”‚  â”‚   â”‚ base_parameters:         â”‚              â”‚         â”‚
â”‚  â”‚   â”‚   catalog, gold_schema,  â”‚              â”‚         â”‚
â”‚  â”‚   â”‚   source_schema          â”‚              â”‚         â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚         â”‚
â”‚  â”‚  schedule: (PAUSED in dev, enabled in prod) â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                          â”‚
â”‚  Updates databricks.yml:                                â”‚
â”‚  â”œâ”€â”€ sync: gold_layer_design/yaml/**/*.yaml             â”‚
â”‚  â”‚   âš ï¸ CRITICAL â€” without sync, setup_tables.py       â”‚
â”‚  â”‚      cannot find YAML schemas on the cluster!        â”‚
â”‚  â”œâ”€â”€ resources: gold_setup_job.yml, gold_merge_job.yml  â”‚
â”‚  â””â”€â”€ environments: serverless + PyYAML dependency       â”‚
â”‚                                                          â”‚
â”‚  ðŸ“ Persist: job YAML paths, databricks.yml sync status â”‚
â”‚  ðŸ—‘ï¸ DISCARD: asset-bundles SKILL.md                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## STOP â€” Artifact Creation Complete

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ðŸ›‘ STOP GATE                           â”‚
â”‚                                                          â”‚
â”‚  Phases 0-3 complete. All scripts and jobs created:     â”‚
â”‚                                                          â”‚
â”‚  src/{project}_gold/                                    â”‚
â”‚  â”œâ”€â”€ setup_tables.py          (Phase 1 â€” generic YAML)  â”‚
â”‚  â”œâ”€â”€ add_fk_constraints.py    (Phase 1 â€” FK application) â”‚
â”‚  â””â”€â”€ merge_gold_tables.py     (Phase 2 â€” all merges)    â”‚
â”‚                                                          â”‚
â”‚  resources/gold/                                        â”‚
â”‚  â”œâ”€â”€ gold_setup_job.yml       (Phase 3 â€” setup + FK)    â”‚
â”‚  â””â”€â”€ gold_merge_job.yml       (Phase 3 â€” periodic merge) â”‚
â”‚                                                          â”‚
â”‚  âš ï¸ Do NOT deploy unless user explicitly requests it    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 4: Deployment (User-Triggered Only)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 4                             â”‚
â”‚                                                          â”‚
â”‚  $ databricks bundle deploy -t dev                      â”‚
â”‚                                                          â”‚
â”‚  Step 1: Setup job (creates tables from YAML)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚ setup_gold_tables    â”‚â”€â”€â”                            â”‚
â”‚  â”‚ (reads YAML â†’ DDL)   â”‚  â”‚ depends_on                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚ add_fk_constraints   â”‚                               â”‚
â”‚  â”‚ (ALTER TABLE FK)     â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                          â”‚
â”‚  Step 2: Verify tables                                  â”‚
â”‚  â”œâ”€â”€ SHOW TABLES IN {catalog}.{gold_schema}             â”‚
â”‚  â”œâ”€â”€ SHOW CREATE TABLE ... (verify PKs)                 â”‚
â”‚  â””â”€â”€ DESCRIBE TABLE EXTENDED ... (verify FKs)           â”‚
â”‚                                                          â”‚
â”‚  Step 3: Merge job (Silver â†’ Gold)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚ merge_gold_tables    â”‚                               â”‚
â”‚  â”‚ (dims first, then    â”‚                               â”‚
â”‚  â”‚  facts â€” dependency  â”‚                               â”‚
â”‚  â”‚  order from YAML FK) â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                          â”‚
â”‚  Step 4: Verify data                                    â”‚
â”‚  â”œâ”€â”€ Record counts per table                            â”‚
â”‚  â”œâ”€â”€ Grain validation (no PK duplicates)                â”‚
â”‚  â”œâ”€â”€ FK integrity (no orphaned references)              â”‚
â”‚  â””â”€â”€ SCD Type 2 checks (one is_current=true per BK)    â”‚
â”‚                                                          â”‚
â”‚  On failure â†’ databricks-autonomous-operations:          â”‚
â”‚  diagnose â†’ fix â†’ redeploy loop                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 4b: Anomaly Detection (User-Triggered)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 4b (optional)                    â”‚
â”‚                                                          â”‚
â”‚  Read: monitoring/04-anomaly-detection/SKILL.md          â”‚
â”‚                                                          â”‚
â”‚  Enable schema-level anomaly detection on Gold schema:  â”‚
â”‚  â”œâ”€â”€ Freshness monitoring (stale Gold table alerts)     â”‚
â”‚  â”œâ”€â”€ Completeness monitoring (missing data alerts)      â”‚
â”‚  â”œâ”€â”€ No exclusions â€” all Gold tables monitored          â”‚
â”‚  â””â”€â”€ Non-blocking: if fails, deployment continues       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 5: Post-Implementation Validation (User-Triggered)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 5                             â”‚
â”‚                                                          â”‚
â”‚  Read: design-workers/05-erd-diagrams/SKILL.md           â”‚
â”‚  (cross-reference created tables against ERD)            â”‚
â”‚                                                          â”‚
â”‚  Validation matrix:                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚  ERD â—„â”€â”€â”€â”€â”€â”€â”€â”€â–º Created Tables           â”‚            â”‚
â”‚  â”‚   â”‚  consistency    â”‚                    â”‚            â”‚
â”‚  â”‚   â”‚  check          â”‚                    â”‚            â”‚
â”‚  â”‚   â–¼                 â–¼                    â”‚            â”‚
â”‚  â”‚  YAML â—„â”€â”€â”€â”€â”€â”€â”€â”€â–º DataFrame Schema        â”‚            â”‚
â”‚  â”‚   â”‚                 â”‚                    â”‚            â”‚
â”‚  â”‚   â–¼                 â–¼                    â”‚            â”‚
â”‚  â”‚  Lineage â—„â”€â”€â”€â”€ Silver Source Tables      â”‚            â”‚
â”‚  â”‚                                          â”‚            â”‚
â”‚  â”‚ âœ… All ERD entities have tables          â”‚            â”‚
â”‚  â”‚ âœ… DataFrame columns match DDL           â”‚            â”‚
â”‚  â”‚ âœ… No PK duplicates (grain valid)        â”‚            â”‚
â”‚  â”‚ âœ… No orphaned FK references             â”‚            â”‚
â”‚  â”‚ âœ… SCD2: one is_current=true per BK      â”‚            â”‚
â”‚  â”‚ âœ… Audit timestamps populated            â”‚            â”‚
â”‚  â”‚ âœ… Conformed dims identical across facts  â”‚            â”‚
â”‚  â”‚ âœ… Advanced patterns validated            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Complete Flow â€” Context Budget Over Time

```
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶

Phase:  â”‚  0  â”‚     1      â”‚        2         â”‚   3   â”‚ 4 â”‚ 5 â”‚

        â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
table   â”‚     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ”‚
inv     â”‚     â”‚  (built)   â”‚                  â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
valid.  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚            â”‚                  â”‚       â”‚   â”‚   â”‚
script  â”‚     â”‚            â”‚                  â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
01-yaml â”‚     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                  â”‚       â”‚   â”‚   â”‚
setup   â”‚     â”‚            â”‚  discarded       â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
tbl-    â”‚     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                  â”‚       â”‚   â”‚   â”‚
props   â”‚     â”‚            â”‚  discarded       â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
unity   â”‚     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                  â”‚       â”‚   â”‚   â”‚
-cat    â”‚     â”‚            â”‚  discarded       â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
schema  â”‚     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚                  â”‚       â”‚   â”‚   â”‚
-mgmt   â”‚     â”‚            â”‚  discarded       â”‚       â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
02-     â”‚     â”‚            â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚       â”‚   â”‚   â”‚
merge   â”‚     â”‚            â”‚                  â”‚disc.  â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
03-     â”‚     â”‚            â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚       â”‚   â”‚   â”‚
dedup   â”‚     â”‚            â”‚                  â”‚disc.  â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
04-     â”‚     â”‚            â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚       â”‚   â”‚   â”‚
grain   â”‚     â”‚            â”‚                  â”‚disc.  â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
05-     â”‚     â”‚            â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚       â”‚   â”‚   â”‚
schema  â”‚     â”‚            â”‚                  â”‚disc.  â”‚   â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
asset   â”‚     â”‚            â”‚                  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚   â”‚   â”‚
bundles â”‚     â”‚            â”‚                  â”‚       â”‚d. â”‚   â”‚
        â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
phase   â”‚     â”‚            â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚â–‘â–‘â–‘â”‚â–‘â–‘â–‘â”‚
notes   â”‚     â”‚  created â†’ â”‚    (10 lines)    â”‚       â”‚   â”‚   â”‚
        â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

 â–ˆâ–ˆâ–ˆ = full skill loaded    â–‘â–‘â–‘ = compact notes (5-10 lines)
```

The Gold Pipeline orchestrator has two distinct peaks:
- **Phase 1:** 1 worker + 3 common skills (table creation)
- **Phase 2:** 4 worker + 1 common skill + 2 references (merge implementation)

Phase 2 is the most skill-intensive phase in the entire orchestrator, but the skills are tightly focused on merge-specific concerns (deduplication, grain, schema validation) and work together as a cohesive unit.

---

## The Pipeline Worker Chain

The 5 pipeline-worker skills form a logical chain that mirrors the merge script's execution order:

```
Phase 0: validate_upstream_contracts.py (no skill)
  â””â”€ Silver â†’ Gold column contract validation
          â”‚
          â–¼
Phase 1: 01-yaml-table-setup
  â””â”€ YAML â†’ DDL generation, table creation, PK/FK constraints
     "Pipeline Notes to Carry Forward":
     - Table inventory dict (names, PKs, FKs, domains)
     - YAML base path for runtime discovery
     - Any constraint failures
          â”‚
          â–¼
Phase 2: 02-merge-patterns (consumed simultaneously with 03, 04, 05)
  â””â”€ SCD Type 1/2 dimension merges, fact aggregation merges
     02-merge: Column mapping, merge conditions, SCD logic
     03-dedup: ALWAYS deduplicate Silver before MERGE
     04-grain: Validate one row per PK after aggregation
     05-schema: Validate DataFrame matches DDL before MERGE
     "Pipeline Notes to Carry Forward":
     - Merge function inventory (SCD1 vs SCD2, agg vs txn)
     - Execution order (dims first, then facts)
     - Any column mapping issues
          â”‚
          â–¼
Phase 3: common/databricks-asset-bundles
  â””â”€ Job YAML, databricks.yml sync, serverless config
          â”‚
          â–¼
Phase 4-5: Deployment and validation (user-triggered)
```

---

## The Extraction Flow â€” YAML as Single Source of Truth

This diagram shows how data flows from YAML into every generated artifact:

```
                    gold_layer_design/yaml/{domain}/{table}.yaml
                    â”‚
                    â”‚ parse
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  table_inventory  â”‚ (in-memory dict)
            â”‚  dict             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚               â”‚                      â”‚
        â–¼           â–¼               â–¼                      â–¼
  setup_tables.py  add_fk_       merge_gold_          gold_*_job.yml
  â”œâ”€â”€ table_name   constraints   tables.py            â”œâ”€â”€ notebook_path
  â”œâ”€â”€ columns      â”œâ”€â”€ FKs      â”œâ”€â”€ pk_columns        â”œâ”€â”€ base_parameters
  â”œâ”€â”€ types        â””â”€â”€ refs     â”œâ”€â”€ business_key       â””â”€â”€ schedule
  â”œâ”€â”€ PKs                       â”œâ”€â”€ scd_type
  â”œâ”€â”€ TBLPROPS                  â”œâ”€â”€ grain
  â””â”€â”€ CLUSTER BY                â”œâ”€â”€ column mappings
     AUTO                       â””â”€â”€ merge conditions
                                         â”‚
                                         â”‚ also reads
                                         â–¼
                                COLUMN_LINEAGE.csv
                                â”œâ”€â”€ silver_col â†’ gold_col
                                â””â”€â”€ transformation_type
```

Every arrow represents an extraction operation â€” the agent reads YAML metadata and builds code from it. The only hand-coded elements are aggregation expressions and derived column formulas (business logic).

---

## Post-Completion: The Audit Trail

| # | Phase | Skill / Reference Read | Type | What It Was Used For |
|---|-------|----------------------|------|---------------------|
| 1 | Phase 0 | `scripts/validate_upstream_contracts.py` | Script | Pre-flight Silver column validation |
| 2 | Phase 1 | `pipeline-workers/01-yaml-table-setup/SKILL.md` | Worker | YAML-to-DDL, find_yaml_base(), PKs |
| 3 | Phase 1 | `common/databricks-table-properties/SKILL.md` | Common | Gold TBLPROPERTIES (CDF, row tracking) |
| 4 | Phase 1 | `common/unity-catalog-constraints/SKILL.md` | Common | PK/FK ALTER TABLE syntax |
| 5 | Phase 1 | `common/schema-management-patterns/SKILL.md` | Common | CREATE SCHEMA IF NOT EXISTS |
| 6 | Phase 2 | `pipeline-workers/02-merge-patterns/SKILL.md` | Worker | SCD1/2, fact aggregation, column mapping |
| 7 | Phase 2 | `pipeline-workers/03-deduplication/SKILL.md` | Worker | Mandatory dedup before MERGE |
| 8 | Phase 2 | `pipeline-workers/04-grain-validation/SKILL.md` | Worker | PK-based grain validation |
| 9 | Phase 2 | `pipeline-workers/05-schema-validation/SKILL.md` | Worker | DataFrameâ†”DDL schema checks |
| 10 | Phase 2 | `common/databricks-python-imports/SKILL.md` | Common | Pure Python modules, no sys.path |
| 11 | Phase 3 | `common/databricks-asset-bundles/SKILL.md` | Common | Job YAML, serverless, notebook_task |
| ... | ... | ... | ... | ... |

---

## Key Design Principles at Work

| # | Principle | How It's Applied |
|---|-----------|-----------------|
| 1 | **YAML as single source of truth** | Every table name, column, PK, FK, SCD type, and grain extracted from YAML at runtime. No hardcoded values. |
| 2 | **Extraction over generation** | `load_table_metadata()` and `load_column_mappings()` replace manual coding. ~70% of column expressions auto-generated from YAML lineage. |
| 3 | **Mandatory deduplication** | EVERY merge function deduplicates Silver before MERGE. Prevents `DELTA_MULTIPLE_SOURCE_ROW_MATCHING_TARGET_ROW_IN_MERGE`. |
| 4 | **Triple validation before merge** | Schema validation (DataFrame matches DDL), grain validation (no PK duplicates), upstream contract validation (Silver columns exist). |
| 5 | **Dimensions before facts** | Merge execution order derived from YAML FK references â€” dimensions first so fact FKs can reference populated dim PKs. |
| 6 | **Generic scripts, no table-specific code** | `setup_tables.py` creates ALL tables from YAML. Adding a table = adding a YAML file, not editing Python. |
| 7 | **Pre-flight contract validation** | Phase 0 catches Silver column mismatches before any code is written â€” the most common source of iteration. |

---

## Common Failure Modes

| Error | Root Cause | Fix |
|-------|-----------|-----|
| `FileNotFoundError: gold_layer_design/yaml/` | YAML files not synced in `databricks.yml` | Add `gold_layer_design/yaml/**/*.yaml` to sync paths |
| `ModuleNotFoundError: yaml` | PyYAML not in job environment | Add `pyyaml>=6.0` to environment spec |
| `DELTA_MULTIPLE_SOURCE_ROW_MATCHING` | Deduplication skipped before MERGE | Add `.dropDuplicates(business_key)` |
| `UNRESOLVED_COLUMN` | Column name hardcoded instead of extracted from YAML | Use `load_column_mappings()` from YAML lineage |
| Grain duplicates after merge | Aggregation didn't match PK grain | Verify `.groupBy()` uses exact PK columns from YAML |
| FK constraint failure | Referenced table/column doesn't exist yet | Run setup job (creates all tables) before FK application |
| Silver column mismatch | YAML lineage references wrong Silver column | Run Phase 0 validation, fix YAML, re-run |

---

## What Happens Next

After Gold implementation is complete and validated:

```
Gold Pipeline (this skill)
    â”‚
    â–¼
Project Planning (00-project-planning)
    â†’ Plan semantic layer, observability, ML, GenAI phases
    â†’ Emit YAML manifests consumed by downstream stages
    â”‚
    â”œâ”€â”€â–¶ Semantic Layer Setup (00-semantic-layer-setup)
    â”‚    â†’ Metric Views from Gold tables
    â”‚    â†’ TVFs for Genie integration
    â”‚    â†’ Genie Spaces with benchmark questions
    â”‚
    â”œâ”€â”€â–¶ Observability Setup (00-observability-setup)
    â”‚    â†’ Lakehouse Monitoring metrics
    â”‚    â†’ Anomaly detection baselines
    â”‚
    â””â”€â”€â–¶ ML / GenAI stages
```

The Gold tables, PKs, FKs, and column descriptions created by this orchestrator become the foundation for the semantic layer (Metric Views reference Gold table schemas) and Genie Spaces (column comments drive natural language understanding).
