# =============================================================================
# Observability Manifest
# =============================================================================
# Generated by: planning/00-project-planning (stage 5)
# Consumed by:  monitoring/00-observability-setup (stage 7)
#
# This manifest defines all Lakehouse Monitors, Anomaly Detection schemas,
# AI/BI Dashboards, and SQL Alerts that the Observability orchestrator should
# create. It is generated from the plan addendums
# (phase1-addendum-1.4-lakehouse-monitoring.md,
# phase1-addendum-1.5-aibi-dashboards.md, phase1-addendum-1.7-alerting.md)
# and the Gold layer YAML schemas.
#
# Usage:
#   1. Fill in the template below during Planning (stage 5)
#   2. Save as: plans/manifests/observability-manifest.yaml
#   3. The observability orchestrator reads this at Phase 0
#   4. This manifest is REQUIRED — the orchestrator will STOP if it is missing
# =============================================================================

version: 2
manifest_type: observability
planning_mode: acceleration  # or "workshop" — downstream orchestrators must not expand beyond listed artifacts
generated_from:
  gold_yaml_dir: gold_layer_design/yaml/
  plan_addendums:
    - plans/phase1-addendum-1.4-lakehouse-monitoring.md
    - plans/phase1-addendum-1.5-aibi-dashboards.md
    - plans/phase1-addendum-1.7-alerting.md

# -----------------------------------------------------------------------------
# Global settings
# -----------------------------------------------------------------------------
catalog: ${catalog}
gold_schema: ${gold_schema}

# -----------------------------------------------------------------------------
# Lakehouse Monitors
# Source: phase1-addendum-1.4-lakehouse-monitoring.md
# -----------------------------------------------------------------------------
lakehouse_monitors:
  # ---------------------------------------------------------------------------
  # Fact table monitors (highest priority — TimeSeries)
  # ---------------------------------------------------------------------------
  - table_name: "fact_{entity}"
    monitor_type: TimeSeries
    timestamp_column: "{timestamp_column}"
    domain: "{domain}"
    use_case_refs:              # Links back to plans/use-case-catalog.md
      - "UC-001"                # {Use case name}
    custom_metrics:
      - name: "{domain}_total_{metric}"
        type: AGGREGATE
        input_columns: [":table"]
        definition: "SUM({metric_column})"
        description: "Total {metric} — business KPI"
      - name: "{domain}_{metric}_trend"
        type: DERIVED
        input_columns:
          - "{domain}_total_{metric}"
        definition: "{{{{domain}_total_{metric}}} / NULLIF(LAG({{{{domain}_total_{metric}}}}) OVER (ORDER BY window), 0)"
        description: "Period-over-period change in {metric}"
    slicing_exprs:
      - "{dimension_1}"
      - "{dimension_2}"

  # ---------------------------------------------------------------------------
  # Dimension table monitors (Snapshot)
  # ---------------------------------------------------------------------------
  - table_name: "dim_{entity}"
    monitor_type: Snapshot
    domain: "{domain}"
    custom_metrics:
      - name: "{domain}_active_{entity}_count"
        type: AGGREGATE
        input_columns: [":table"]
        definition: "COUNT(CASE WHEN is_current = TRUE THEN 1 END)"
        description: "Count of active {entity} records"

# -----------------------------------------------------------------------------
# Anomaly Detection (Schema-Level)
# Uses the Data Quality API (Public Preview) for freshness/completeness monitoring.
# Each schema entry enables anomaly detection via w.data_quality.create_monitor().
# The orchestrator uses schema UUID (not three-level name) as object_id.
# -----------------------------------------------------------------------------
anomaly_detection:
  schemas:
    - schema_name: "${gold_schema}"
      description: "Gold layer — monitor all fact and dimension tables for freshness/completeness"
      excluded_tables:
        # Tables to skip (staging, quarantine, temp tables)
        # - "staging_raw"
        # - "temp_processing"

    # Add additional schemas as needed (e.g., Silver layer):
    # - schema_name: "${silver_schema}"
    #   description: "Silver layer — baseline freshness monitoring"
    #   excluded_tables:
    #     - "dq_rules"

# -----------------------------------------------------------------------------
# AI/BI Dashboards
# Source: phase1-addendum-1.5-aibi-dashboards.md
# Organized by domain
# -----------------------------------------------------------------------------
dashboards:
  - name: "{Domain} Performance Dashboard"
    domain: "{domain}"
    description: "Operational dashboard for {domain} metrics and data quality"
    use_case_refs:              # Links back to plans/use-case-catalog.md
      - "UC-001"                # {Use case name}
    pages:
      - page_name: "Overview"
        widgets:
          - title: "Total {Metric}"
            type: counter
            query_table: "fact_{entity}"
          - title: "{Metric} Trend"
            type: line_chart
            query_table: "fact_{entity}"
            x_axis: "{date_column}"
            y_axis: "{metric_column}"
      - page_name: "Data Quality"
        widgets:
          - title: "Monitor Health"
            type: table
            query_source: "{table}_profile_metrics"
          - title: "Drift Indicators"
            type: bar_chart
            query_source: "{table}_drift_metrics"

  - name: "Unified Monitoring Dashboard"
    domain: "cross-domain"
    description: "Cross-domain monitoring overview across all Gold tables"
    pages:
      - page_name: "Monitor Summary"
        widgets:
          - title: "All Monitors Status"
            type: table
            query_source: "all monitor profile tables"
          - title: "Data Quality Score"
            type: counter
            query_source: "derived from profile metrics"

# -----------------------------------------------------------------------------
# SQL Alerts
# Source: phase1-addendum-1.7-alerting.md
# Organized by domain, then by severity
# -----------------------------------------------------------------------------
alerts:
  # ---------------------------------------------------------------------------
  # Domain alerts
  # ---------------------------------------------------------------------------
  - alert_id: "{DOM}-001-CRIT"
    domain: "{domain}"
    severity: critical
    name: "{Domain} {Metric} Threshold Alert"
    use_case_refs:              # Links back to plans/use-case-catalog.md
      - "UC-001"                # {Use case name}
    type: threshold
    query: |
      SELECT COUNT(*) as alert_count
      FROM ${catalog}.${gold_schema}.fact_{entity}
      WHERE {metric_column} > {threshold_value}
        AND {date_column} >= CURRENT_DATE - INTERVAL 1 DAY
    threshold: 0
    operator: ">"
    schedule: "0 */15 * * *"  # Every 15 minutes
    notification_destination: "{pagerduty_or_slack}"

  - alert_id: "{DOM}-002-WARN"
    domain: "{domain}"
    severity: warning
    name: "{Domain} Data Freshness Alert"
    type: threshold
    query: |
      SELECT TIMESTAMPDIFF(HOUR, MAX({timestamp_column}), CURRENT_TIMESTAMP()) as hours_stale
      FROM ${catalog}.${gold_schema}.fact_{entity}
    threshold: 4
    operator: ">"
    schedule: "0 0 * * *"  # Daily
    notification_destination: "{email_or_slack}"

  - alert_id: "{DOM}-003-WARN"
    domain: "{domain}"
    severity: warning
    name: "{Domain} {Metric} Percentage Change Alert"
    type: percentage_change
    query: |
      SELECT
        today.total_{metric} as current_value,
        yesterday.total_{metric} as previous_value,
        ((today.total_{metric} - yesterday.total_{metric}) / NULLIF(yesterday.total_{metric}, 0)) * 100 as pct_change
      FROM (
        SELECT SUM({metric_column}) as total_{metric}
        FROM ${catalog}.${gold_schema}.fact_{entity}
        WHERE {date_column} = CURRENT_DATE
      ) today
      CROSS JOIN (
        SELECT SUM({metric_column}) as total_{metric}
        FROM ${catalog}.${gold_schema}.fact_{entity}
        WHERE {date_column} = CURRENT_DATE - 1
      ) yesterday
    threshold: 25
    operator: ">"
    schedule: "0 8 * * *"  # Daily at 8 AM
    notification_destination: "{email}"

# -----------------------------------------------------------------------------
# Summary counts (for validation)
# Fill in after populating all domains
# -----------------------------------------------------------------------------
summary:
  total_monitors: "{N}"
  total_anomaly_detection_schemas: "{N}"
  total_dashboards: "{N}"
  total_dashboard_pages: "{N}"
  total_alerts: "{N}"
  alerts_by_severity:
    critical: "{N}"
    warning: "{N}"
    info: "{N}"
